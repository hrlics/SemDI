{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A quick evaluation on ESC and CTB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import load_from_disk\n",
    "from model import Causal_Model\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from utils import compute_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = 'google-bert/bert-large-uncased'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "special_tokens_dict = {'additional_special_tokens': ['<e1>','</e1>','<e2>','</e2>']}\n",
    "tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "def tokenize_function_mask(examples):\n",
    "    return tokenizer(examples[\"event_masked_sentence\"], truncation=True)\n",
    "\n",
    "def tokenize_function_tag(examples):\n",
    "    return tokenizer(examples[\"event_tagged_sentence\"], truncation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ESC evaluation demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fold =load_from_disk('dataset/ESC/ESC_test_fold4')\n",
    "\n",
    "masked_test_fold = test_fold.map(tokenize_function_mask, batched=True, batch_size=32)\n",
    "masked_test_fold = masked_test_fold.remove_columns(['sentence', 'event_tagged_sentence', 'event_masked_sentence','e1','e2'])\n",
    "masked_test_fold.set_format(\"torch\")\n",
    "\n",
    "tagged_test_fold = test_fold.map(tokenize_function_tag, batched=True, batch_size=32)\n",
    "tagged_test_fold = tagged_test_fold.remove_columns(['sentence', 'event_tagged_sentence', 'event_masked_sentence','e1','e2'])\n",
    "tagged_test_fold.set_format(\"torch\")\n",
    "\n",
    "print(f\"test len: {len(masked_test_fold)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_btz=20\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "dataloader_mask_test = DataLoader(\n",
    "masked_test_fold, shuffle=False, batch_size=test_btz, collate_fn=data_collator)\n",
    "dataloader_tag_test = DataLoader(\n",
    "tagged_test_fold, shuffle=False,  batch_size=test_btz, collate_fn=data_collator)\n",
    "\n",
    "dataloader_mask_test = tqdm(dataloader_mask_test, dynamic_ncols=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda'\n",
    "model=Causal_Model(bert_path=checkpoint, d_model=1024, num_heads=16, dropout_rate=0.5, device='cuda', visualize=False)\n",
    "\n",
    "model.load_state_dict(torch.load('./model_checkpoints/ESC/best_model_fold4.pt'))\n",
    "model=model.to(device)\n",
    "criterion=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "mean_loss_test = 0\n",
    "predicted_all_test = []\n",
    "gold_all_test = []\n",
    "with torch.no_grad():\n",
    "    iteration=0\n",
    "    for mask_data, tag_data in zip(dataloader_mask_test, dataloader_tag_test):\n",
    "        mask_data, tag_data=mask_data.to(device), tag_data.to(device)\n",
    "        labels=tag_data['labels']\n",
    "        labels=labels.to(device)\n",
    "\n",
    "        del mask_data['labels']\n",
    "        del tag_data['labels']\n",
    "        \n",
    "        outputs=model(mask_data, tag_data).squeeze(1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        mean_loss_test = (mean_loss_test * iteration + loss.detach()) / (iteration + 1)\n",
    "        iteration+=1\n",
    "\n",
    "        predicted = torch.argmax(outputs, dim=-1)\n",
    "        predicted=list(predicted.cpu().numpy())\n",
    "        predicted_all_test+=predicted\n",
    "        gold_all_test+=list(labels.cpu().numpy())\n",
    "                                                    \n",
    "precision_t, recall_t, f1_score_t = compute_metrics(gold_all_test, predicted_all_test)\n",
    "print(f\"[test ESC fold 4] p:{precision_t*100:.2f} r:{recall_t*100:.2f} F1:{f1_score_t*100:.2f} loss:{mean_loss_test.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CTB evaluation demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fold =load_from_disk('dataset/CTB/CTB_test_fold2')\n",
    "\n",
    "masked_test_fold = test_fold.map(tokenize_function_mask, batched=True, batch_size=32)\n",
    "masked_test_fold = masked_test_fold.remove_columns(['sentence', 'event_tagged_sentence', 'event_masked_sentence','e1','e2'])\n",
    "masked_test_fold.set_format(\"torch\")\n",
    "\n",
    "tagged_test_fold = test_fold.map(tokenize_function_tag, batched=True, batch_size=32)\n",
    "tagged_test_fold = tagged_test_fold.remove_columns(['sentence', 'event_tagged_sentence', 'event_masked_sentence','e1','e2'])\n",
    "tagged_test_fold.set_format(\"torch\")\n",
    "\n",
    "print(f\"test len: {len(masked_test_fold)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_btz=20\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "dataloader_mask_test = DataLoader(\n",
    "masked_test_fold, shuffle=False, batch_size=test_btz, collate_fn=data_collator)\n",
    "dataloader_tag_test = DataLoader(\n",
    "tagged_test_fold, shuffle=False,  batch_size=test_btz, collate_fn=data_collator)\n",
    "\n",
    "dataloader_mask_test = tqdm(dataloader_mask_test, dynamic_ncols=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda'\n",
    "model=Causal_Model(bert_path=checkpoint, d_model=1024, num_heads=16, dropout_rate=0.5, device='cuda', visualize=False)\n",
    "\n",
    "model.load_state_dict(torch.load('./model_checkpoints/CTB/best_model_fold2.pt'))\n",
    "model=model.to(device)\n",
    "criterion=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "mean_loss_test = 0\n",
    "predicted_all_test = []\n",
    "gold_all_test = []\n",
    "with torch.no_grad():\n",
    "    iteration=0\n",
    "    for mask_data, tag_data in zip(dataloader_mask_test, dataloader_tag_test):\n",
    "        mask_data, tag_data=mask_data.to(device), tag_data.to(device)\n",
    "        labels=tag_data['labels']\n",
    "        labels=labels.to(device)\n",
    "\n",
    "        del mask_data['labels']\n",
    "        del tag_data['labels']\n",
    "        \n",
    "        outputs=model(mask_data, tag_data).squeeze(1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        mean_loss_test = (mean_loss_test * iteration + loss.detach()) / (iteration + 1)\n",
    "        iteration+=1\n",
    "\n",
    "        predicted = torch.argmax(outputs, dim=-1)\n",
    "        predicted=list(predicted.cpu().numpy())\n",
    "        predicted_all_test+=predicted\n",
    "        gold_all_test+=list(labels.cpu().numpy())\n",
    "                                                    \n",
    "precision_t, recall_t, f1_score_t = compute_metrics(gold_all_test, predicted_all_test)\n",
    "print(f\"[test CTB fold 2] p:{precision_t*100:.2f} r:{recall_t*100:.2f} F1:{f1_score_t*100:.2f} loss:{mean_loss_test.item():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MINE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
